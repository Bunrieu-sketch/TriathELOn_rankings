{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete data extraction from ITU API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.special import binom\n",
    "# Path hack.\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "# import heloer functions for cleaning df\n",
    "from src.helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- have all years of data read in here\n",
    "- have all years data cleaned and organized in a separate notebook\n",
    "- get rid of mixed relay\n",
    "- Hamburg MALE 2018 is missing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get all race results, each race needs a `program ID` and an `event ID`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = os.environ['ITU_API']\n",
    "\n",
    "# THIS GIVES EVENT ID\n",
    "url = \"https://api.triathlon.org/v1/events?category_id=351&start_date=2011-01-01&end_date=2019-12-31\"\n",
    "\n",
    "headers = {'apikey': password}\n",
    "\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "\n",
    "races_2010s = (response.json())['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create all the required directories to hold the races\n",
    "- only need to run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [\"2012_races\",\"2013_races\", \"2014_races\", \n",
    "        \"2015_races\", \"2016_races\",\"2017_races\", \"2018_races\", \"2019_races\"]\n",
    "for path in dirs:\n",
    "    path1 = path+\"/races\"\n",
    "    path2 = path+\"/races_clean\"\n",
    "    path3 = path=\"/ovo_races\"\n",
    "    for path in [path1, path2, path3]:\n",
    "        os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Program ID for all WTS races  - do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS GIVES PROGRAM ID for ALL WTS races\n",
    "url = \"https://api.triathlon.org/v1/statistics/results?analysis=count_unique&target_property=event.name&group_by=event.name|program.id|program.name\"\n",
    "headers = {'apikey': password}\n",
    "response = requests.request(\"GET\", url, headers=headers)\n",
    "all_events  = response.json()['data']['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = [year for year in range(2009,2020)]\n",
    "period = 1\n",
    "for year in year_list:\n",
    "    if period > 1:\n",
    "        period +=5\n",
    "    # get the Event ID of races from that year!\n",
    "    url = f\"https://api.triathlon.org/v1/events?category_id=351&start_date={year}-01-01&end_date={year}-12-31\"\n",
    "    headers = {'apikey': password}\n",
    "\n",
    "    response = requests.request(\"GET\", url, headers=headers)\n",
    "    races = (response.json())['data']\n",
    "    \n",
    "    # dict to store event and program ID of all races during the season\n",
    "    season_dict = defaultdict(list)\n",
    "    # /get race name and race event ID\n",
    "    for race in races:\n",
    "        if len(re.findall('Relay', race['event_title'])) == 0:\n",
    "            season_dict[race['event_title']].append(race['event_id'])\n",
    "    # map race event ID with program ID\n",
    "    for event in all_events:\n",
    "        if (event['event.name']) in season_dict.keys():\n",
    "            season_dict[event['event.name']].append((event['program.id'], event['program.name']))\n",
    "            \n",
    "    # have program and event ID from all races, so can get and store all results\n",
    "    # get the results each race in our season \n",
    "    for key, values in season_dict.items():\n",
    "        if (len(values) == 3):\n",
    "            # race location\n",
    "            race_name = re.findall('\\s(\\w+)$', key)[0]    \n",
    "            if (race_name == 'Triathlon'):\n",
    "                race_name = key.split(' ')[1]\n",
    "            # event ID\n",
    "            event_id = values[0]   \n",
    "\n",
    "            for program_id in (values[1], values[2]):\n",
    "                prog_id = program_id[0]\n",
    "                gender = 'female' if program_id[1] == 'Elite Women' else 'male'\n",
    "\n",
    "                # get those specific results\n",
    "                url = f\"https://api.triathlon.org/v1/events/{event_id}/programs/{prog_id}/results\"\n",
    "                response = requests.request(\"GET\", url, headers=headers)\n",
    "                race_result = response.json()['data']['results']\n",
    "\n",
    "                # store all the attributes of each race in a dictionary of lists\n",
    "                race = defaultdict(list)\n",
    "                for athlete in race_result:\n",
    "                    race['program_id'].append(prog_id)\n",
    "                    race['athlete_id'].append(athlete['athlete_id'])\n",
    "                    race['athlete_first'].append(athlete['athlete_first'])\n",
    "                    race['athlete_last'].append(athlete['athlete_last'])\n",
    "                    race['nationality'].append(athlete['athlete_noc'])\n",
    "                    race['start_number'].append(athlete['start_num'])\n",
    "                    race['swim'].append(athlete['splits'][0])\n",
    "                    race['t1'].append(athlete['splits'][1])\n",
    "                    race['bike'].append(athlete['splits'][2])\n",
    "                    race['t2'].append(athlete['splits'][3])\n",
    "                    race['run'].append(athlete['splits'][4])\n",
    "                    race['position'].append(athlete['position'])\n",
    "                    race['total_time'].append(athlete['total_time'])\n",
    "\n",
    "                # turn the dict into a df\n",
    "                race_df = pd.DataFrame(race)\n",
    "                \n",
    "                # clean df\n",
    "                clean_df = clean_dataframe(race_df, ['swim', 't1', 'bike', 't2', 'total_time'])\n",
    "                \n",
    "                # ovo DF (for use in glicko func)\n",
    "                ovo_df = one_vs_one(race_df, int(period))\n",
    "            \n",
    "                # write all to file\n",
    "                race_df.to_csv(f\"{year}_races/races/{race_name}_{gender}.csv\", index = False)\n",
    "                clean_df.to_csv(f\"{year}_races/races_clean/{race_name}_{gender}.csv\", index = False)\n",
    "                ovo_df.to_csv(f\"{year}_races/ovo_races/{race_name}_{gender}.csv\", index = False)       \n",
    "                \n",
    "                # update time period of race\n",
    "                # adding half so every two races (M and F) iterates by 1\n",
    "                period += 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_period():\n",
    "    \"\"\"\n",
    "    Check a few cases to make sure working\n",
    "    \"\"\"\n",
    "    gc09_ovo_male = pd.read_csv(\"2009_races/ovo_races/Coast_male.csv\")\n",
    "    gc09_ovo_fmale = pd.read_csv(\"2009_races/ovo_races/Coast_female.csv\")\n",
    "    syd10_ovo_male = pd.read_csv(\"2010_races/ovo_races/Sydney_male.csv\")\n",
    "    syd10_ovo_female = pd.read_csv(\"2010_races/ovo_races/Sydney_female.csv\")\n",
    "    syd11_ovo_male = pd.read_csv(\"2011_races/ovo_races/Sydney_male.csv\")\n",
    "    syd12_ovo_male = pd.read_csv(\"2012_races/ovo_races/Sydney_male.csv\")\n",
    "    \n",
    "    \n",
    "    assert(gc09_ovo_male.iloc[0][0] == 8), \"Time period incorrect\"\n",
    "    assert(gc09_ovo_female.iloc[0][0] == 8), \"Time period incorrect\"\n",
    "    assert(syd10_ovo_male.iloc[0][0] == 14), \"Time period incorrect\"\n",
    "    assert(syd10_ovo_female.iloc[0][0] == 14), \"Time period incorrect\"\n",
    "    assert(syd11_ovo_male.iloc[0][0] == 26), \"Time period incorrect\"\n",
    "    assert(syd12_ovo_male.iloc[0][0] == 39), \"Time period incorrect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_period()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
